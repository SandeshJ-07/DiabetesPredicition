# Create your views here.
# -*- coding: utf-8 -*-
"""Diabetes Prediction using SVM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1o3p2iFv4v6qs1CnWc5_LgPDpUvmsrPVJ

Importing the Dependencies
"""
from pathlib import Path
import os
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn import svm
from sklearn.metrics import accuracy_score
from django.shortcuts import render
from django.http import HttpResponse
from django.views.decorators.csrf import csrf_exempt

"""Data Collection and Analysis

PIMA Diabetes Dataset
"""
@csrf_exempt
def API(request):
    if request.POST:
        # loading the diabetes dataset to a pandas DataFrame
        BASE_DIR = Path(__file__).resolve().parent.parent
        print(os.path.join(BASE_DIR,'diabetes.csv'))
        diabetes_dataset = pd.read_csv(os.path.join(BASE_DIR,'diabetes.csv'))
        # pd.read_csv?

        # printing the first 5 rows of the dataset
        diabetes_dataset.head()

        # number of rows and Columns in this dataset
        diabetes_dataset.shape

        # getting the statistical measures of the data
        diabetes_dataset.describe()

        diabetes_dataset['Outcome'].value_counts()

        """0 --> Non-Diabetic

        1 --> Diabetic
        """

        diabetes_dataset.groupby('Outcome').mean()

        # separating the data and labels
        X = diabetes_dataset.drop(columns = 'Outcome', axis=1)
        Y = diabetes_dataset['Outcome']

        print(X)

        print(Y)

        """Data Standardization"""

        scaler = StandardScaler()

        scaler.fit(X)

        standardized_data = scaler.transform(X)

        print(standardized_data)

        X = standardized_data
        Y = diabetes_dataset['Outcome']

        print(X)
        print(Y)

        """Train Test Split"""

        X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.1, stratify=Y, random_state=2)

        print(X.shape, X_train.shape, X_test.shape)

        """Training the Model"""

        classifier = svm.SVC(kernel='linear')

        #training the support vector Machine Classifier
        classifier.fit(X_train, Y_train)

        """Model Evaluation

        Accuracy Score
        """

        # accuracy score on the training data
        X_train_prediction = classifier.predict(X_train)
        training_data_accuracy = accuracy_score(X_train_prediction, Y_train)

        print('Accuracy score of the training data : ', training_data_accuracy)

        # accuracy score on the test data
        X_test_prediction = classifier.predict(X_test)
        test_data_accuracy = accuracy_score(X_test_prediction, Y_test)

        print('Accuracy score of the test data : ', test_data_accuracy)

        """Making a Predictive System"""

        x = request.POST
        # input_data = (5,166,72,19,175,25.8,0.587,51)
        try:
            input_data = (int(x["pregnancies"]), float(x["glucose"]), float(x["bloodPressure"]), float(x["skinThickness"]),float(x["insulin"]), float(x["BMI"]),float(x["DiabetesPedigreeFunction"]) , int(x["age"]))
        except:
            return HttpResponse("Error Parsing Values")

        # changing the input_data to numpy array
        input_data_as_numpy_array = np.asarray(input_data)

        # reshape the array as we are predicting for one instance
        input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

        # standardize the input data
        std_data = scaler.transform(input_data_reshaped)
        print(std_data)

        prediction = classifier.predict(std_data)
        print(prediction)

        if (prediction[0] == 0):
            return HttpResponse('The person is not diabetic')
        else:
            return HttpResponse('The person is diabetic')